# -*- coding: utf-8 -*-
"""exploring_tensorflow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AVpJNPdSiQSi8xygwBxI1f76lvair5_q
"""

!pip install gputil
!pip install psutil

import csv
import gc
import math 
import numpy
import os
import time
import psutil


import GPUtil as gpuUtil
import pandas as pd
import tensorflow as tf
import threading
import textwrap

from keras import backend as K 
from IPython.display import clear_output
from matplotlib import pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import SGDClassifier
from sklearn import preprocessing
from sklearn import utils
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import GradientBoostingClassifier

class MonitoringInfo:
  def __init__(self):
    self.platform = ""
    self.cpu_count = 0
    self.disk_value = 0
    self.gpu_load = 0
    self.ram_value = 0
    self.ram_total = 0
    self.ram_utilization = 0

class Monitor(threading.Thread):
  # Do this per algorithm as opposed to the entire program.
    def __init__(self, delay):
        super(Monitor, self).__init__()
        self.stopped = False
        self.delay = delay # Time between calls to GPUtil
        self.start()
        
        self.monitor_data = {}
        self.time_interval = 0
        

    def run(self):
        while not self.stopped:
            gpus_enabled = False            
            process = psutil.Process(os.getpid())
            monitoringInfo = MonitoringInfo()
          
            try:              
                gpu = gpuUtil.getGPUs()[0]

                monitoringInfo.cpu_count = psutil.cpu_count()
                monitoringInfo.platform = gpu.name
                monitoringInfo.gpu_load = gpu.load*100
                monitoringInfo.ram_value = gpu.memoryUsed
                monitoringInfo.ram_total = gpu.memoryTotal
                monitoringInfo.ram_utilization = gpu.memoryUtil*100

                gpus_enabled = True
                             
            except ValueError:
              # GPU may not be enabled in the runtime environmnent so we pass.
              pass

            if not gpus_enabled:
              monitoringInfo.cpu_count = psutil.cpu_count()
              
              monitoringInfo.ram_value = psutil.virtual_memory()[5] / (pow(1024,3))
              monitoringInfo.ram_total = psutil.virtual_memory()[1] / (pow(1024,3))
              monitoringInfo.ram_utilization =  monitoringInfo.ram_value / monitoringInfo.ram_total
              
              monitoringInfo.disk_value = psutil.disk_usage('/')[1] / (pow(1024,3))
            
            self.monitor_data[self.time_interval] = monitoringInfo
            self.time_interval += 1

            time.sleep(self.delay)


    def stop(self):
        self.stopped = True


def getProcessedDatasetFromUrl(lab):
  url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.{name}.data'.format(name=lab)
  print("url", url)
  column_names = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 
                    'oldpeak', 'slope', 'ca', 'thal', 'num']
 
  raw_dataset = pd.read_csv(url, names=column_names,
                          na_values='?', comment='\t',
                          sep=',', skipinitialspace=True)
  dataset = raw_dataset.copy()

  return dataset


def imputeDataset(dataset):
  if not dataset.isnull().any().any():
    return dataset

  threshold = int(dataset.shape[0] / 2)
  dataset = dataset.dropna(axis=1, thresh=threshold, how="any")
  dataset = dataset.fillna(dataset.median())
  return dataset


def getTrainTestValidateSplit(dataset):
  dataset = utils.shuffle(dataset, random_state=0)

  train = dataset[:math.ceil(len(dataset) * (0.5))]
  validate = dataset[len(train) : (len(train) + math.ceil(len(dataset) * (0.3))) ]
  test = dataset[(len(train) + len(validate)):]

  return train, test, validate


def getRepresentativeSampleArchetype(test_features, true_samples_indices):
  sess = tf.compat.v1.Session()
  with sess.as_default():
    true_predictions = tf.gather_nd(test_features, true_samples_indices)
    
    if tf.executing_eagerly():
      true_predictions_dataframe = pd.DataFrame(data=true_predictions.numpy(), columns=test_features.columns)
    else:
      true_predictions_dataframe = pd.DataFrame(data=true_predictions.eval(), columns=test_features.columns)

    mean = pd.Series.mean(true_predictions_dataframe)
    mode = true_predictions_dataframe.mode(axis=0, dropna=True).iloc[0]

  return mean, mode



def combineDatasets(imputed_cleveland_dataset, imputed_hungarian_dataset,
                    imputed_switzerland_dataset, imputed_long_beach_dataset):
  
  a = imputed_cleveland_dataset 
  b = imputed_long_beach_dataset 
  c = imputed_switzerland_dataset
  d = imputed_hungarian_dataset

  a_cols = set(a.columns)
  b_cols = set(b.columns)
  c_cols = set(c.columns)
  d_cols = set(d.columns)

  merge = pd.concat([a, b, c, d], join='outer', axis=0)
  merge = merge.dropna(axis=1, how="any")
    
  return merge



processed_cleveland_dataset =  getProcessedDatasetFromUrl("cleveland")
imputed_cleveland_dataset = imputeDataset(processed_cleveland_dataset)

processed_switzerland_dataset =  getProcessedDatasetFromUrl("switzerland")
imputed_switzerland_dataset = imputeDataset(processed_switzerland_dataset)

processed_hungarian_dataset =  getProcessedDatasetFromUrl("hungarian")
imputed_hungarian_dataset = imputeDataset(processed_hungarian_dataset)

processed_long_beach_dataset =  getProcessedDatasetFromUrl("va")
imputed_long_beach_dataset = imputeDataset(processed_long_beach_dataset)


datasets = [imputed_cleveland_dataset, imputed_hungarian_dataset,
              imputed_switzerland_dataset, imputed_long_beach_dataset]

names = ["imputed_cleveland_dataset",  "imputed_hungarian_dataset",
           "imputed_switzerland_dataset", "imputed_long_beach_dataset"]

combined_dataset = combineDatasets(imputed_cleveland_dataset, imputed_hungarian_dataset,
                    imputed_switzerland_dataset, imputed_long_beach_dataset)


def printMonitorData(monitor, subject):
  print("\nMonitoring Data for: ", subject)

  count_monitored_time_entries = len(list(monitor.monitor_data.keys()))
  if count_monitored_time_entries == 0:
    print("No time intervals captured")
    return
  
  time_intervals = []
  cpu_counts = []
  gpus = []
  disk = []
  ram_used = []
  ram_totals = []
  ram_utils = []

  for k in list(monitor.monitor_data.keys()):
    time_intervals += [k]
    cpu_counts += [monitor.monitor_data[k].cpu_count]
    gpus += [monitor.monitor_data[k].gpu_load]
    disk += [monitor.monitor_data[k].disk_value]
    ram_used += [monitor.monitor_data[k].ram_value]
    ram_totals += [monitor.monitor_data[k].ram_total]
    ram_utils += [monitor.monitor_data[k].ram_utilization]


  print("printing plot")
  plt.plot(time_intervals, cpu_counts, label="cpus")
  plt.plot(time_intervals, gpus, label="gpus")
  plt.plot(time_intervals, disk, label="disk")
  plt.xlabel("Time Interval")
  plt.ylabel("Count")
  plt.title("CPU, GPU & Disk")
  plt.legend()
  plt.show()


  plt.plot(time_intervals, ram_used, label="used ram")
  plt.plot(time_intervals, ram_totals, label="total ram")
  plt.xlabel("Time Interval")
  plt.ylabel("Gigabyte")
  plt.title("Ram Usage")
  plt.legend()
  plt.show()

  plt.plot(time_intervals, ram_utils, label = "ram utilization")
  plt.xlabel("Time Interval")
  plt.ylabel("Percent")
  plt.title("Ram Utilization")
  plt.legend()
  plt.show()

  print("Max Ram Used: ", max(ram_used))
  print("Max Ram Utilization: ", max(ram_utils))
  print("Max GPU: ", max(gpus))
  print("Max CPU: ", max(cpu_counts))


def main():
  tf.logging.set_verbosity(tf.logging.FATAL)

  # Instantiate monitor with a 10-second delay between updates
  
  monitor = Monitor(5)      
  
  for dataset, dataset_name in zip(datasets, names):
    print("\n\n")
    evaluateLogisticRegression(dataset.copy(), dataset_name)
    evaluateKnn(dataset.copy(), dataset_name)
    evaluateGradientBoosting(dataset.copy(), dataset_name)
  
  print("\n\n")
  evaluateLogisticRegression(combined_dataset.copy(), "Combined Dataset")
  evaluateKnn(combined_dataset.copy(), "Combined Dataset")
  evaluateGradientBoosting(combined_dataset.copy(), "Combined Dataset")
  
  monitor.stop()
  printMonitorData(monitor)

  return


# Remove comment to execute all cells
#main()

def doLogisticRegression(train_features, train_labels, test_features, test_labels):
  tf.get_logger().setLevel('FATAL')

  with tf.compat.v1.Session():
    tf_logistic_regression_monitor = Monitor(0.25)      
    start_time = time.time()
      
    normalized_train = tf.keras.utils.normalize(train_features.copy())
    normalized_test_features = tf.keras.utils.normalize(test_features.copy())

    model = tf.keras.Sequential()
    model.add(tf.keras.layers.Dense(1, input_shape=train_features.to_numpy()[0].shape, activation='sigmoid'))
    model.compile(optimizer='sgd', loss='mean_squared_error', metrics=['accuracy'])

    model.fit(
        normalized_train,
        train_labels,
        shuffle=True,
    )
    
    predictions = model.predict(normalized_test_features)
    
    # Logistic regression computes likeliness, we need to convert this to classes
    # Using 0.5 because that's the split for diameter narrowing for the dataset
    # 'num' column - our target value.
    new_labels = []
    for p in predictions:
        if p > 0.5:
            new_labels += [1]
        else:
            new_labels += [0]
            
    equals = (tf.equal(test_labels, new_labels))
    equals_as_ints = tf.cast(equals, tf.int32)
    equals_count = tf.reduce_sum(equals_as_ints)

    if tf.executing_eagerly():
      print("Tensorflow accuracy = ", equals_count.numpy() / len(test_labels))
    else:
      print("Tensorflow accuracy = ", equals_count.eval() / len(test_labels))
    

    # Determine and print model archetypical true sample
    true_samples_indices = tf.where(equals)
    print("Archetype of a True prediction:")
    mean_archetype, mode_archetype = getRepresentativeSampleArchetype(test_features, true_samples_indices)

    print("Mean Archetpye:")
    print(mean_archetype)
    print("Mode Archetype:")
    print(mode_archetype)

    tf_logistic_regression_monitor.stop()
    end_time = time.time()
    elapsed_time = end_time - start_time
    print("Elapsed Time: {t:.2F}ms".format(t=(elapsed_time * 1000)))
    printMonitorData(tf_logistic_regression_monitor, "Tensorflow Logistic Regression") 

  
  gc.collect()
  tf.compat.v1.reset_default_graph()
  K.clear_session()

  return

    
    
def doSkLearnLogisticRegression(train_features, train_labels, test_features, test_labels): 
  with tf.compat.v1.Session():
    sklearn_logistic_regression_monitor = Monitor(0.25)      
    start_time = time.time()
  
    scaler = preprocessing.StandardScaler().fit(train_features)
    train_features_scaled = scaler.transform(train_features)
    test_features_scaled = scaler.transform(test_features)

    model = SGDClassifier(loss='log').fit(train_features_scaled, train_labels)
    predictions = model.predict(test_features_scaled)

    print("sklearn accuracy = ", model.score(test_features_scaled, test_labels))
    
    sklearn_logistic_regression_monitor.stop()
    end_time = time.time()
    elapsed_time = end_time - start_time
    print("Elapsed Time: {t:.2F}ms".format(t=(elapsed_time * 1000)))
    
    # Allow monitoring thread to process.
    time.sleep(2)
    printMonitorData(sklearn_logistic_regression_monitor,"SkLearn Logistic Regression") 

    equals = (tf.equal(test_labels, predictions))
    true_samples_indices = tf.where(equals)
    print("Archetype of a True prediction:")
    mean_archetype, mode_archetype = getRepresentativeSampleArchetype(test_features, true_samples_indices)

    print("Mean Archetpye:")
    print(mean_archetype)
    print("Mode Archetype:")
    print(mode_archetype)

  gc.collect()
  tf.compat.v1.reset_default_graph()
  K.clear_session()

  return

  
def evaluateLogisticRegression(dataset, dataset_name):
  print("\nEvaluate Logistic Regression for: ", dataset_name)
  tf.get_logger().setLevel('FATAL')

  train_dataset = dataset.sample(frac=0.66, random_state=0)
  test_dataset = dataset.drop(train_dataset.index)
    
  train_features = train_dataset.copy()
  test_features = test_dataset.copy()

  train_labels = train_features.pop('num')
  train_labels = train_labels.replace([1,2,3,4], 1)
  test_labels = test_features.pop('num')
  test_labels = test_labels.replace([1,2,3,4], 1)

 
  doLogisticRegression(train_features, train_labels, test_features, test_labels)
  doSkLearnLogisticRegression(train_features, train_labels, test_features, test_labels)

  return

for dataset, dataset_name in zip(datasets, names):
  print("\n\n\n")
  evaluateLogisticRegression(dataset.copy(), dataset_name)

print("\n\n\n")
evaluateLogisticRegression(combined_dataset.copy(), "Combined Dataset")

def executeKnnOnDataSet(k, train_dataset, train_features, train_labels, 
                        validate_dataset, validate_features, validate_labels, mode=None):
  
  tf_nearest_neighbors_monitor = Monitor(0.25)      
  start_time = time.time()
    
  sess = tf.compat.v1.Session()
  with sess.as_default():
    predictedLabels = []
    for i in range(len(validate_dataset)):
      computeDistance = tf.math.reduce_euclidean_norm(train_dataset - validate_dataset[i], axis=1) 
      findKClosestSamples = tf.argsort(computeDistance, direction='ASCENDING') 
      findLabelsKClosestSamples = tf.gather(train_labels, findKClosestSamples[0:k])
      uniqueLabels, indices, counts = tf.unique_with_counts(findLabelsKClosestSamples) # examine labels of k closest Train images

      # Take the most frequently occuring label as the predicted value.
      findPredictedLabel = tf.gather(uniqueLabels, tf.argmax(counts))
      if tf.executing_eagerly():
        predictedLabels += [findPredictedLabel.numpy()]
      else:
        predictedLabels += [findPredictedLabel.eval()]
      

    tf_nearest_neighbors_monitor.stop()

    equals = tf.equal(predictedLabels, validate_labels)
    equals_as_ints = tf.cast(equals, tf.int32)
    equals_count = tf.reduce_sum(equals_as_ints)
    
    if tf.executing_eagerly():
      accuracy = equals_count.numpy() / len(validate_labels)
    else:
      accuracy = equals_count.eval() / len(validate_labels)
      

    if mode == "test":
      print("Tensorflow accuracy = ", accuracy)
      true_samples_indices = tf.where(equals)
      print("Archetype of a True prediction:")
      mean_archetype, mode_archetype = getRepresentativeSampleArchetype(validate_features, true_samples_indices)

      print("Mean Archetpye:")
      print(mean_archetype)
      print("Mode Archetype:")
      print(mode_archetype)   

      end_time = time.time()
      elapsed_time = end_time - start_time
      print("Elapsed Time: {t:.2F}ms".format(t=(elapsed_time * 1000)))
      printMonitorData(tf_nearest_neighbors_monitor,"Tensorflow Nearest Neighbors")

  
  gc.collect()
  tf.compat.v1.reset_default_graph()
  K.clear_session()

  return accuracy



def determineOptimalK(train_dataset, train_features, train_labels, 
                        validate_dataset, validate_features, validate_labels):

  accuracyToK = {}  
  optimalK = 1

  for k in range(1, len(validate_dataset)):
    accuracy = executeKnnOnDataSet(k, train_dataset, train_features, train_labels, 
                        validate_dataset, validate_features, validate_labels)
   
    accuracyToK[accuracy] = k

  highestAccuracy = max(accuracyToK.keys())
  bestK = accuracyToK[highestAccuracy]

  return bestK


def doSkLearnKNearestNeighbors(optimalK, train_features, train_labels, 
                        test_features, test_labels):
  sklearn_nearest_neighbors_monitor = Monitor(0.25)      
  start_time = time.time()
 
  knnClassifier = KNeighborsClassifier(n_neighbors = optimalK)

  knnClassifier.fit(train_features, train_labels)
  predictions = knnClassifier.predict(test_features)

  print("sklearn accuracy = ", knnClassifier.score(test_features, test_labels))

  sklearn_nearest_neighbors_monitor.stop()
  end_time = time.time()
  elapsed_time = end_time - start_time
  print("Elapsed Time: {t:.2F}ms".format(t=(elapsed_time * 1000)))

  # Allow monitoring thread to process.
  time.sleep(2)
  printMonitorData(sklearn_nearest_neighbors_monitor,"SkLearn Nearest Neighbors") 

  equals = (tf.equal(test_labels, predictions))
  true_samples_indices = tf.where(equals)
  print("Archetype of a True prediction:")
  mean_archetype, mode_archetype = getRepresentativeSampleArchetype(test_features, true_samples_indices)

  print("Mean Archetpye:")
  print(mean_archetype)
  print("Mode Archetype:")
  print(mode_archetype)
  
  return 


def evaluateKnn(dataset, dataset_name):
  print("\nEvaluate KNN for: ", dataset_name)
  tf.get_logger().setLevel('FATAL')

  train_dataset, validate_dataset, test_dataset = getTrainTestValidateSplit(dataset)

  train_features = train_dataset.copy()
  train_labels = train_features.pop('num')
  
  validate_features = validate_dataset.copy()
  validate_labels = validate_features.pop('num')

  test_features = test_dataset.copy()
  test_labels = test_features.pop('num')
  
  train_dataset = numpy.array(train_dataset)
  validate_dataset = numpy.array(validate_dataset)
  test_dataset = numpy.array(test_dataset)
  
  
  optimalK = determineOptimalK(train_dataset, train_features, train_labels, 
                        validate_dataset, validate_features, validate_labels)
  
  print("Optimal k = ", optimalK)


  executeKnnOnDataSet(optimalK, train_dataset, train_features, train_labels, 
                        test_dataset, test_features, test_labels, mode='test')
    
  doSkLearnKNearestNeighbors(11, train_features, train_labels, 
                        test_features, test_labels)
  

  return
  
for dataset, dataset_name in zip(datasets, names):
  print("\n\n\n")
  evaluateKnn(dataset.copy(), dataset_name)

print("\n\n\n")
evaluateKnn(combined_dataset.copy(), "Combined Dataset")

def one_hot_cat_column(feature_name, vocab):
    return tf.feature_column.indicator_column(
      tf.feature_column.categorical_column_with_vocabulary_list(feature_name,
                                                 vocab))

def make_input_fn(X, y, num_examples, n_epochs=None, shuffle=True):
    def input_fn():
        dataset = tf.data.Dataset.from_tensor_slices((dict(X), y))
        if shuffle:
            dataset = dataset.shuffle(num_examples)
        # For training, cycle thru dataset as many times as need (n_epochs=None).
        dataset = dataset.repeat(n_epochs)
        # In memory training doesn't use batching.
        dataset = dataset.batch(num_examples)
        return dataset
    return input_fn


def doGradientBoostingRegression(train_features, train_labels, test_features, test_labels):
  sess = tf.compat.v1.Session()
  with sess.as_default():
    tf.get_logger().setLevel('FATAL')
    tf.compat.v1.disable_v2_behavior()
    
    tf_gradient_boosting_monitor = Monitor(0.25)
    start_time = time.time()

    feature_columns = []
    for feature_name in train_features.columns:
      feature_columns.append(tf.feature_column.numeric_column(feature_name,
                                            dtype=tf.float32))

    # Training and evaluation input functions.
    train_input_fn = make_input_fn(train_features, train_labels, len(train_labels))
    eval_input_fn = make_input_fn(test_features, test_labels, len(test_labels), shuffle=False, n_epochs=1)

    # Default learning_rate=0.1, which yields different results for TF vs scikit-learn
    est = tf.estimator.BoostedTreesClassifier(feature_columns,
                                              #learning_rate=0.01,
                                              n_classes=len(feature_columns),
                                              n_batches_per_layer=1)
  
    est.train(train_input_fn, max_steps=100)
    stats = est.evaluate(eval_input_fn)
    result = est.predict(eval_input_fn)

    pred_dicts = list(result)
    predictions = [pred['class_ids'][0] for pred in pred_dicts]
    
    print("\n\nGB Tree Stats:")
    print(pd.Series(stats))

    tf_gradient_boosting_monitor.stop()
    end_time = time.time()
    elapsed_time = end_time - start_time
    print("Elapsed Time = {t:.2F}ms".format(t=(elapsed_time * 1000)))
    printMonitorData(tf_gradient_boosting_monitor,"Tensorflow Gradient Boosting") 


    equals = (tf.equal(test_labels, predictions))
    true_samples_indices = tf.where(equals)
    print("Archetype of a True prediction:")
    mean_archetype, mode_archetype = getRepresentativeSampleArchetype(test_features, true_samples_indices)

    print("Mean Archetpye:")
    print(mean_archetype)
    print("Mode Archetype:")
    print(mode_archetype)


  gc.collect()
  tf.compat.v1.reset_default_graph()
  K.clear_session()

  return


def doSkLearnGradientBoosting(train_features, train_labels, test_features, test_labels):
  with tf.compat.v1.Session():
    sklearn_gradient_boosting_monitor = Monitor(0.25)      
    start_time = time.time()

    # Default learning_rate=0.1, which yields different results for TF vs scikit-learn
    classifier = GradientBoostingClassifier(random_state=0) #,  learning_rate=0.01)
    classifier.fit(train_features, train_labels)

    #GradientBoostingClassifier(random_state=0)

    predictions = classifier.predict(test_features)

    print("\n\nSkLearn Accuracy = ", classifier.score(test_features, test_labels))

    sklearn_gradient_boosting_monitor.stop()
    
    end_time = time.time()
    elapsed_time = end_time - start_time
    print("Elapsed Time: {t:.2F}ms".format(t=(elapsed_time * 1000)))
    
    # Allow monitoring thread to process.
    time.sleep(2)
    printMonitorData(sklearn_gradient_boosting_monitor,"SkLearn Gradient Boosting") 


    equals = (tf.equal(test_labels, predictions))
    true_samples_indices = tf.where(equals)
    print("Archetype of a True prediction:")
    mean_archetype, mode_archetype = getRepresentativeSampleArchetype(test_features, true_samples_indices)

    print("Mean Archetpye:")
    print(mean_archetype)
    print("Mode Archetype:")
    print(mode_archetype)

  gc.collect()
  tf.compat.v1.reset_default_graph()
  K.clear_session()

  return


def evaluateGradientBoosting(dataset, dataset_name):
  print("\nEvaluate Gradient Boosting: ", dataset_name)

  train_dataset = dataset.sample(frac=0.66, random_state=0)
  test_dataset = dataset.drop(train_dataset.index)
    
  train_features = train_dataset.copy()
  test_features = test_dataset.copy()

  train_labels = train_features.pop('num')
  test_labels = test_features.pop('num')

  doGradientBoostingRegression(train_features, train_labels, test_features, test_labels)
  doSkLearnGradientBoosting(train_features, train_labels, test_features, test_labels)

  return

  
for dataset, dataset_name in zip(datasets, names):
  print("\n\n\n")
  evaluateGradientBoosting(dataset.copy(), dataset_name)

print("\n\n\n")
evaluateGradientBoosting(combined_dataset.copy(), "Combined Dataset")

for dataset, dataset_name in zip(datasets, names):
  print("dataset_name = ", dataset_name)
  print("shape = ", dataset.shape)

print("shape = ", combined_dataset.shape)

